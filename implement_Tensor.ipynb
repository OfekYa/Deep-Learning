{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+8B4Df38BMVew16wrUHGS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OfekYa/Deep-Learning/blob/main/implement_Tensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1: An implementation of a Tensor constructor that samples random numbers from a discrete distribution that is received in the input.\n",
        "# Q2: An implementation of an automatic derivation system. The system will follow mathematical operations performed on the variables and calculate together with each operation its immediate derivative"
      ],
      "metadata": {
        "id": "Oe0slIjEJSVR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q1:  my_sampler**"
      ],
      "metadata": {
        "id": "QTsQyxLmquLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "\n",
        "\"\"\"Checking that the sum of the probabilities is 1 and that every element in the vector is positive\"\"\"\n",
        "def is_distribution_valid(dist):\n",
        "    if (torch.all(dist > 0) and dist.sum() == 1.0):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def my_sampler(size, dist, requires_grad=False):\n",
        "\n",
        "    dist = torch.tensor(dist)  # Convert the list \"dist\" to be tensor type.\n",
        "    if is_distribution_valid(dist) == False:  # check validity of the distribution\n",
        "        raise Exception('The given distribution is not valid.')\n",
        "\n",
        "    dist = dist.cumsum(dim=0)  # Now each element in tensor \"dist\" holds the sum of the probabilities up to that element.\n",
        "    sum_P_n = dist[-2]  # The sum of the probabilities up to the value: n-1.\n",
        "    prev_sum_P_i = 0  # The sum of the probabilities up to the previous value: i-1.\n",
        "\n",
        "    probabilities_tensor = torch.rand(size)  # Each element in the probabilities_tensor is a U that holds a value between 0 and 1.\n",
        "\n",
        "    \"\"\" Initialize all I's to 0:  -->  I = 0.\n",
        "        If a certain condition is met on U:  --> condition(U) == TRUE.\n",
        "            then a placement is made on I:  -->  I = (I + k) or (I + n)   \"\"\"\n",
        "    result_tensor = torch.zeros(size)  # if (U < P(0)) then (I = 0).  a tensor of zeros will solve this requirement.\n",
        "\n",
        "    \"\"\" Step 2 in the algorithm:\n",
        "        if the value of the random variable is greater than or equal to the sum of the first n-1 probabilities:\n",
        "            then we will return I = n \"\"\"\n",
        "    mask_by_condition_2 = (probabilities_tensor >= sum_P_n)  # if (U >= sum_P(n-1)) then (I is TRUE).\n",
        "    n = mask_by_condition_2 * (len(dist) - 1)  # if (I is TRUE) then (I = n), else (I keeps the value 0).\n",
        "    result_tensor = result_tensor + n  # Update the output tensor according to the elements that will be defined n.\n",
        "\n",
        "    \"\"\" Steps 3 and 4 in the algorithm:\n",
        "        if the value of the random variable is greater than or equal to the sum of the \n",
        "           first k-1 probabilities and smaller than the sum of the first k probabilities:\n",
        "            then we will return I = k \"\"\"\n",
        "    for i in range(len(dist)-1):\n",
        "\n",
        "        curr_sum_P_i = dist[i]  # The sum of the probabilities up to the current value: i.\n",
        "\n",
        "        mask3_1 = (probabilities_tensor >= prev_sum_P_i)  # if (U >= sum_P(i-1)) then (I is TRUE).\n",
        "        mask3_2 = (probabilities_tensor < curr_sum_P_i)  # if (U < sum_P(i)) then (I is TRUE).\n",
        "        mask_by_condition_3 = mask3_1 & mask3_2   # if (sum_P(i) > U >= sum_P(i-1)) then (I is TRUE).\n",
        "        k = mask_by_condition_3 * i  # if (I is TRUE) then (I = k), else (I remains 0 or n).\n",
        "        result_tensor = result_tensor + k  # Update the output tensor according to the elements that will be defined k.\n",
        "\n",
        "        prev_sum_P_i = dist[i]  # Update the sum of the probabilities up to the previous value: i-1.\n",
        "\n",
        "    result_tensor.requires_grad_(requires_grad)\n",
        "    return result_tensor\n"
      ],
      "metadata": {
        "id": "UnEr2kiKqtio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Q1:**"
      ],
      "metadata": {
        "id": "z-oatroprHwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TEST 1\")\n",
        "A = my_sampler(10,[0.5,0.5])\n",
        "print(A)\n",
        "\n",
        "print(\"TEST 2\")\n",
        "B = my_sampler((2,10), [0.1,0.2,0.7], requires_grad = True)\n",
        "print(B,B.grad,sep='\\n')\n",
        "\n",
        "\n",
        "x = my_sampler(10000, [0.1,0.2,0.7])\n",
        "plt.hist(x)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "ZIzT1xUHrQh9",
        "outputId": "4047bef4-1113-4f6c-9fc2-576a292acfce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST 1\n",
            "tensor([0., 0., 0., 1., 1., 1., 1., 0., 1., 0.])\n",
            "TEST 2\n",
            "tensor([[2., 2., 2., 2., 0., 2., 1., 2., 2., 2.],\n",
            "        [2., 0., 2., 2., 2., 2., 2., 2., 1., 2.]], requires_grad=True)\n",
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q2: MyScalar**\n"
      ],
      "metadata": {
        "id": "x0CiQZ-6qUoC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkW3OqQoR6S_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class MyScalar:\n",
        "\n",
        "    def __init__(self, scalar_value, gradient_value = 1, parent = None):\n",
        "        self.value = scalar_value\n",
        "        self.gradient = gradient_value\n",
        "        self.parent = parent\n",
        "        self.parent_gradient = 1  # cumulative gradient value.\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"\\nMyScalar (scalar value: {float(self.value)} ,gradient value:{float(self.gradient)} ,parent: {self.parent})\"\n",
        "\n",
        "\n",
        "    def __add__(self, other):\n",
        "        value = torch.tensor(self.value + other)\n",
        "        gradient = 1\n",
        "        return MyScalar(value, gradient, self)\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        value = torch.tensor(other * self.value)\n",
        "        grad = other\n",
        "        return MyScalar(value, grad, self)\n",
        "\n",
        "    def __pow__(self, power):\n",
        "        value = torch.tensor(self.value ** power)\n",
        "        grad = power * (self.value ** (power - 1))\n",
        "        return MyScalar(value, grad, self)\n",
        "\n",
        "    def cosine(self):\n",
        "        value = torch.cos(self.value)\n",
        "        grad = -(torch.sin(self.value))\n",
        "        return MyScalar(value, grad, self)\n",
        "\n",
        "    def sine(self):\n",
        "        value = torch.sin(self.value)\n",
        "        grad = torch.cos(self.value)\n",
        "        return MyScalar(value, grad, self)\n",
        "\n",
        "    def ln(self):\n",
        "        value = torch.log(self.value)  # Returns a new tensor with the natural logarithm of the elements of input.\n",
        "        grad = 1 / self.value\n",
        "        return MyScalar(value, grad, self)\n",
        "\n",
        "    def exp(self):\n",
        "        value = torch.exp(torch.tensor(self.value))\n",
        "        grad = value\n",
        "        return MyScalar(value, grad, self)\n",
        "\n",
        "\n",
        "    def get_gradient(self):\n",
        "\n",
        "        if self.parent is not None:\n",
        "            gradient_dic[self] = self.parent_gradient\n",
        "            self.parent.parent_gradient = self.gradient * self.parent_gradient\n",
        "            MyScalar.get_gradient(self.parent)\n",
        "        else: # אם self.parents = None אז הגענו לשורש הרקורסיה, כלומר לאיבר הראשון שבוצעה עליו פעולה\n",
        "            gradient_dic[self] = self.gradient * self.parent_gradient\n",
        "\n",
        "        return gradient_dic\n",
        "\n",
        "\n",
        "gradient_dic = {}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TEST Math Functions:**"
      ],
      "metadata": {
        "id": "eManwCLeS9dE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = MyScalar(4)\n",
        "torch_x = torch.tensor([4.])\n",
        "print(\"x: \", x)\n",
        "print(\"torch_x: \", torch_x)\n",
        "\n",
        "a = MyScalar.__add__(x, 3)\n",
        "torch_a = torch.add(torch_x, 3)\n",
        "print(\"\\na: \", a.value)\n",
        "print(\"torch_a: \", torch_a)\n",
        "\n",
        "b = MyScalar.__mul__(x, 3)\n",
        "torch_b = torch.mul(torch_x, 3)\n",
        "print(\"\\nb: \", b.value)\n",
        "print(\"torch_b: \", torch_b)\n",
        "\n",
        "c = MyScalar.__pow__(x, 2)\n",
        "torch_c = torch.pow(torch_x, 2)\n",
        "print(\"\\nc: \", c.value)\n",
        "print(\"torch_c: \", torch_c)\n",
        "\n",
        "d = MyScalar.exp(x)\n",
        "torch_d = torch.exp(torch_x)\n",
        "print(\"\\nd: \", d.value)\n",
        "print(\"torch_d: \", torch_d)\n",
        "\n",
        "e = MyScalar.ln(d)\n",
        "torch_e = torch.log(torch_d)\n",
        "print(\"\\ne: \", e.value)\n",
        "print(\"torch_e: \", torch_e)\n",
        "\n",
        "f = MyScalar.cosine(e)\n",
        "torch_f = torch.cos(torch_e)\n",
        "print(\"\\nf: \", f.value)\n",
        "print(\"torch_f: \", torch_f)\n",
        "\n",
        "g = MyScalar.sine(f)\n",
        "torch_g = torch.sin(torch_f)\n",
        "print(\"\\ng: \", g.value)\n",
        "print(\"torch_g: \", torch_g)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3jOL1x7S47C",
        "outputId": "cdb11ab8-a92c-4c81-fffc-773d63f0060f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x:  \n",
            "MyScalar (scalar value: 4.0 ,gradient value:1.0 ,parent: None)\n",
            "torch_x:  tensor([4.])\n",
            "\n",
            "a:  tensor(7)\n",
            "torch_a:  tensor([7.])\n",
            "\n",
            "b:  tensor(12)\n",
            "torch_b:  tensor([12.])\n",
            "\n",
            "c:  tensor(16)\n",
            "torch_c:  tensor([16.])\n",
            "\n",
            "d:  tensor(54.5981)\n",
            "torch_d:  tensor([54.5981])\n",
            "\n",
            "e:  tensor(4.)\n",
            "torch_e:  tensor([4.])\n",
            "\n",
            "f:  tensor(-0.6536)\n",
            "torch_f:  tensor([-0.6536])\n",
            "\n",
            "g:  tensor(-0.6081)\n",
            "torch_g:  tensor([-0.6081])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TEST get_gradient:**"
      ],
      "metadata": {
        "id": "d_XKZ_SWTN4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = MyScalar(2)\n",
        "b = MyScalar.__pow__(a, 2)\n",
        "c = MyScalar.exp(b)\n",
        "#d = MyScalar.cosine(c)\n",
        "#e = MyScalar.ln(d)\n",
        "f = MyScalar.get_gradient(c)\n",
        "print(\"f: \", f)\n",
        "\n",
        "\n",
        "torch_a = torch.tensor([2.], requires_grad=True)\n",
        "torch_b = torch.pow(torch_a, 2)\n",
        "torch_c = torch.exp(torch_b)\n",
        "#torch_d = torch.cos(torch_c)\n",
        "#torch_e = torch.log(torch_d)\n",
        "\n",
        "torch_c.backward()\n",
        "print(\"torch_a: \", torch_a.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJBw2GshSvV0",
        "outputId": "9aa3a7a9-eb19-4a27-a188-280a6c138325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f:  {\n",
            "MyScalar (scalar value: 54.598148345947266 ,gradient value:54.598148345947266 ,parent: \n",
            "MyScalar (scalar value: 4.0 ,gradient value:4.0 ,parent: \n",
            "MyScalar (scalar value: 2.0 ,gradient value:1.0 ,parent: None))): 1, \n",
            "MyScalar (scalar value: 4.0 ,gradient value:4.0 ,parent: \n",
            "MyScalar (scalar value: 2.0 ,gradient value:1.0 ,parent: None)): tensor(54.5981), \n",
            "MyScalar (scalar value: 2.0 ,gradient value:1.0 ,parent: None): tensor(218.3926)}\n",
            "torch_a:  tensor([218.3926])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-4b7a813d6a4f>:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  value = torch.exp(torch.tensor(self.value))\n"
          ]
        }
      ]
    }
  ]
}